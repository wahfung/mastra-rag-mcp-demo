import express from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import { Mastra } from '@mastra/core';
import { RAGEngine } from '@mastra/rag';
import { deepseek } from '@ai-sdk/deepseek';
import { generateText } from 'ai';

dotenv.config();

const app = express();
const port = process.env.PORT || 3000;

app.use(cors());
app.use(express.json());

// DeepSeek æ¨¡å‹é…ç½®
const llmModel = deepseek('deepseek-chat');

// Mastra é…ç½® - ç»Ÿä¸€ç®¡ç† RAG å’Œå·¥å…·
const mastra = new Mastra({
  tools: [
    {
      name: 'query_knowledge',
      description: 'æŸ¥è¯¢çŸ¥è¯†åº“',
      inputSchema: {
        type: 'object',
        properties: {
          question: { type: 'string', description: 'è¦æŸ¥è¯¢çš„é—®é¢˜' }
        },
        required: ['question']
      },
      execute: async ({ question }: { question: string }) => {
        const startTime = Date.now();
        
        try {
          const ragEngine = mastra.getEngine('rag') as RAGEngine;
          const searchResults = await ragEngine.search({
            query: question,
            topK: 5,
            threshold: 0.7
          });

          const context = searchResults.map(result => result.content).join('\n\n');
          
          const { text: answer } = await generateText({
            model: llmModel,
            system: 'ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œèƒ½å¤ŸåŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜æ— æ³•æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚',
            prompt: `åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ï¼š\n\nä¸Šä¸‹æ–‡:\n${context}\n\né—®é¢˜: ${question}\n\nè¯·æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ï¼š`,
            temperature: 0.7,
            maxTokens: 1000,
          });

          return {
            answer,
            sources: searchResults.map(result => ({
              content: result.content,
              metadata: result.metadata,
              similarity: result.similarity
            })),
            processingTime: Date.now() - startTime,
            model: 'deepseek-chat'
          };
        } catch (error) {
          console.error('RAGæŸ¥è¯¢é”™è¯¯:', error);
          throw new Error(`æŸ¥è¯¢å¤±è´¥: ${error.message}`);
        }
      }
    },
    {
      name: 'add_document',
      description: 'æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“',
      inputSchema: {
        type: 'object',
        properties: {
          content: { type: 'string', description: 'æ–‡æ¡£å†…å®¹' },
          metadata: { type: 'object', description: 'æ–‡æ¡£å…ƒæ•°æ®' }
        },
        required: ['content']
      },
      execute: async ({ content, metadata }: { content: string; metadata?: any }) => {
        try {
          const ragEngine = mastra.getEngine('rag') as RAGEngine;
          const result = await ragEngine.addDocument({
            content,
            metadata: {
              ...metadata,
              timestamp: new Date().toISOString(),
              addedBy: 'mastra-rag-demo'
            }
          });
          
          return {
            id: result.id,
            chunks: result.chunks || 1,
            processed: true,
            timestamp: new Date().toISOString()
          };
        } catch (error) {
          console.error('æ–‡æ¡£æ·»åŠ é”™è¯¯:', error);
          throw new Error(`æ–‡æ¡£æ·»åŠ å¤±è´¥: ${error.message}`);
        }
      }
    },
    {
      name: 'chat_with_deepseek',
      description: 'ç›´æ¥ä¸ DeepSeek æ¨¡å‹å¯¹è¯',
      inputSchema: {
        type: 'object',
        properties: {
          message: { type: 'string', description: 'è¦å‘é€çš„æ¶ˆæ¯' },
          system: { type: 'string', description: 'ç³»ç»Ÿæç¤ºï¼ˆå¯é€‰ï¼‰' }
        },
        required: ['message']
      },
      execute: async ({ message, system }: { message: string; system?: string }) => {
        try {
          const { text: response } = await generateText({
            model: llmModel,
            system: system || 'ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚',
            prompt: message,
            temperature: 0.7,
            maxTokens: 1000,
          });

          return {
            response,
            model: 'deepseek-chat',
            timestamp: new Date().toISOString()
          };
        } catch (error) {
          console.error('DeepSeekå¯¹è¯é”™è¯¯:', error);
          throw new Error(`å¯¹è¯å¤±è´¥: ${error.message}`);
        }
      }
    }
  ],
  engines: {
    rag: new RAGEngine({
      vectorDB: {
        provider: 'pinecone',
        config: {
          url: process.env.VECTOR_DB_URL
        }
      },
      embedder: {
        provider: 'openai', // ä»…ç”¨äºåµŒå…¥
        model: 'text-embedding-3-small',
        apiKey: process.env.OPENAI_API_KEY
      },
      llm: {
        provider: 'custom', // ä½¿ç”¨ DeepSeek
        model: 'deepseek-chat',
        generateFn: async (prompt: string, options: any) => {
          const { text } = await generateText({
            model: llmModel,
            prompt,
            temperature: options.temperature || 0.7,
            maxTokens: options.maxTokens || 1000,
          });
          return text;
        }
      }
    })
  }
});

// REST API ç«¯ç‚¹
app.get('/health', (req, res) => {
  res.json({ 
    status: 'healthy', 
    timestamp: new Date().toISOString(),
    model: 'deepseek-chat',
    version: '1.0.0'
  });
});

app.post('/query', async (req, res) => {
  try {
    const { question } = req.body;
    if (!question) {
      return res.status(400).json({ error: 'é—®é¢˜ä¸èƒ½ä¸ºç©º' });
    }
    
    const result = await mastra.executeTool('query_knowledge', { question });
    res.json(result);
  } catch (error) {
    console.error('æŸ¥è¯¢é”™è¯¯:', error);
    res.status(500).json({ error: 'æŸ¥è¯¢å¤±è´¥', details: error.message });
  }
});

app.post('/documents', async (req, res) => {
  try {
    const { content, metadata } = req.body;
    if (!content) {
      return res.status(400).json({ error: 'æ–‡æ¡£å†…å®¹ä¸èƒ½ä¸ºç©º' });
    }
    
    const result = await mastra.executeTool('add_document', { content, metadata });
    res.json(result);
  } catch (error) {
    console.error('æ–‡æ¡£æ·»åŠ é”™è¯¯:', error);
    res.status(500).json({ error: 'æ–‡æ¡£æ·»åŠ å¤±è´¥', details: error.message });
  }
});

app.post('/chat', async (req, res) => {
  try {
    const { message, system } = req.body;
    if (!message) {
      return res.status(400).json({ error: 'æ¶ˆæ¯ä¸èƒ½ä¸ºç©º' });
    }
    
    const result = await mastra.executeTool('chat_with_deepseek', { message, system });
    res.json(result);
  } catch (error) {
    console.error('å¯¹è¯é”™è¯¯:', error);
    res.status(500).json({ error: 'å¯¹è¯å¤±è´¥', details: error.message });
  }
});

// å·¥å…·æ¥å£
app.get('/tools', async (req, res) => {
  try {
    const tools = mastra.tools.map(tool => ({
      name: tool.name,
      description: tool.description,
      inputSchema: tool.inputSchema
    }));
    res.json({ 
      tools,
      model: 'deepseek-chat',
      provider: '@ai-sdk/deepseek'
    });
  } catch (error) {
    res.status(500).json({ error: 'è·å–å·¥å…·åˆ—è¡¨å¤±è´¥' });
  }
});

app.post('/tools/:toolName', async (req, res) => {
  try {
    const { toolName } = req.params;
    const args = req.body;
    
    const result = await mastra.executeTool(toolName, args);
    res.json({ result });
  } catch (error) {
    console.error('å·¥å…·æ‰§è¡Œé”™è¯¯:', error);
    res.status(500).json({ error: 'å·¥å…·æ‰§è¡Œå¤±è´¥', details: error.message });
  }
});

// å¯åŠ¨æœåŠ¡å™¨
async function startServer() {
  try {
    await mastra.initialize();
    
    app.listen(port, () => {
      console.log(`ğŸš€ Mastra RAG Demo (DeepSeek) è¿è¡Œåœ¨ç«¯å£ ${port}`);
      console.log(`ğŸ“Š å¥åº·æ£€æŸ¥: http://localhost:${port}/health`);
      console.log(`ğŸ” RAG æŸ¥è¯¢: POST http://localhost:${port}/query`);
      console.log(`ğŸ“„ æ–‡æ¡£ä¸Šä¼ : POST http://localhost:${port}/documents`);
      console.log(`ğŸ’¬ DeepSeek å¯¹è¯: POST http://localhost:${port}/chat`);
      console.log(`ğŸ› ï¸  å·¥å…·åˆ—è¡¨: GET http://localhost:${port}/tools`);
      console.log(`âš¡ å·¥å…·æ‰§è¡Œ: POST http://localhost:${port}/tools/:toolName`);
      
      console.log(`\nğŸ› ï¸  å¯ç”¨å·¥å…·:`);
      console.log(`  - query_knowledge: æ™ºèƒ½é—®ç­” (RAG + DeepSeek)`);
      console.log(`  - add_document: æ–‡æ¡£ç®¡ç†`);
      console.log(`  - chat_with_deepseek: ç›´æ¥å¯¹è¯`);
      
      console.log(`\nğŸ¤– AI æ¨¡å‹: DeepSeek Chat`);
      console.log(`ğŸ“¦ æä¾›å•†: @ai-sdk/deepseek`);
      console.log(`ğŸ”§ æ¡†æ¶: Mastra + AI SDK`);
      console.log(`âœ¨ çŠ¶æ€: æ—  modelcontextprotocol ä¾èµ–`);
    });
  } catch (error) {
    console.error('æœåŠ¡å™¨å¯åŠ¨å¤±è´¥:', error);
    process.exit(1);
  }
}

startServer();